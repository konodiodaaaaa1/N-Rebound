import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import os
import akshare as ak

# ==========================================
# ğŸ“ è·¯å¾„è¡¥ä¸
# ==========================================
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# --- âš™ï¸ é…ç½® ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
LOOKBACK_WINDOW = 30
FEATURE_SIZE = 5
MODEL_PATH = "n_rebound_model.pth"
DATA_DIR = "training_data"  # é¡ºæ‰‹å­˜æ•°æ®çš„åœ°æ–¹

if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)


# ==========================================
# ğŸ§  æ¨¡å‹æ¶æ„ (å¿…é¡»ä¸è®­ç»ƒä¸€è‡´)
# ==========================================
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (
                -10.46 / d_model))  # math.log(10000.0) approx 9.21, adjusting slightly or using numpy/math
        import math
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x): return x + self.pe[:x.size(0), :]


class NReboundTransformer(nn.Module):
    def __init__(self, input_size=5, d_model=64, nhead=4, num_layers=2, dropout=0.2):
        super(NReboundTransformer, self).__init__()
        self.embedding = nn.Linear(input_size, d_model)
        self.pos_encoder = PositionalEncoding(d_model)
        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)
        self.decoder = nn.Sequential(
            nn.Linear(d_model * LOOKBACK_WINDOW, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, src):
        src = src.permute(1, 0, 2)
        src = self.embedding(src)
        src = self.pos_encoder(src)
        output = self.transformer_encoder(src)
        output = output.permute(1, 0, 2)
        output = output.reshape(output.size(0), -1)
        prob = self.decoder(output)
        return prob.squeeze()


# ==========================================
# ğŸ”® æ¨ç†ç±»
# ==========================================
class AIFilter:
    def __init__(self):
        self.model = None
        self.load_model()

    def load_model(self):
        if not os.path.exists(MODEL_PATH):
            return
        try:
            self.model = NReboundTransformer()
            self.model.load_state_dict(
                torch.load(MODEL_PATH, map_location=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
                           weights_only=True))
            self.model.to(DEVICE)
            self.model.eval()
        except Exception:
            pass

    def predict(self, code):
        """
        è¾“å…¥: è‚¡ç¥¨ä»£ç  (å¦‚ 600519)
        è¾“å‡º: (åˆ†æ•°0-100, å»ºè®®æ–‡æœ¬, è¯¦ç»†æ•°æ®DataFrame)
        """
        if self.model is None: return 0, "æ¨¡å‹æœªåŠ è½½", None

        try:
            # 1. æ„é€ ä»£ç 
            sina_symbol = f"sh{code}" if code.startswith('6') else f"sz{code}"

            # 2. å®æ—¶æ‹‰å– (é¢„æµ‹å¿…é¡»ç”¨æœ€æ–°çš„)
            df = ak.stock_zh_a_daily(symbol=sina_symbol, adjust="qfq")

            if df is None or df.empty or len(df) < LOOKBACK_WINDOW:
                return 0, "æ•°æ®ä¸è¶³(ä¸Šå¸‚æ—¶é—´å¤ªçŸ­)", None

            # 3. é¡ºæ‰‹å­˜ä¸€ä»½åˆ°æœ¬åœ°ç¼“å­˜ (ç§¯ç´¯æ•°æ®)
            # csv_path = os.path.join(DATA_DIR, f"{code}.csv")
            # df.to_csv(csv_path, index=False, encoding='utf_8_sig')

            # 4. é¢„å¤„ç†
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values(by='date').reset_index(drop=True)

            # å–æœ€å 30 å¤©
            slice_df = df.tail(LOOKBACK_WINDOW)

            # å½’ä¸€åŒ– (ä¸è®­ç»ƒä¸€è‡´)
            vals = slice_df[['open', 'high', 'low', 'close', 'volume']].values.astype(np.float32)
            base_price = vals[0, 0]
            if base_price == 0: base_price = 1e-6
            price_feats = vals[:, 0:4] / base_price - 1

            base_vol = np.mean(vals[:, 4])
            if base_vol == 0: base_vol = 1e-6
            vol_feat = vals[:, 4:5] / base_vol - 1

            features = np.hstack([price_feats, vol_feat])

            # 5. æ¨ç†
            tensor_x = torch.tensor(features).unsqueeze(0)
            tensor_x = tensor_x.to(DEVICE)
            with torch.no_grad():
                prob = self.model(tensor_x).item()

            score = round(prob * 100, 1)

            # è¯æœ¯ç”Ÿæˆ
            if score > 70:
                advice = "ğŸ”¥ æä½³ (å¼ºåŠ›æ¨è)"
            elif score > 60:
                advice = "âœ… è‰¯å¥½ (å¯ä»¥è€ƒè™‘)"
            elif score > 50:
                advice = "ğŸ¤” ä¸€èˆ¬ (èƒœç‡äº”äº”å¼€)"
            else:
                advice = "âŒ è¾ƒå·® (å»ºè®®è§‚æœ›)"

            return score, advice, slice_df

        except Exception as e:
            return 0, f"åˆ†æå‡ºé”™: {str(e)}", None


if __name__ == "__main__":
    ai = AIFilter()
    s, m, _ = ai.predict("600519")
    print(f"Test: {s} - {m}")
